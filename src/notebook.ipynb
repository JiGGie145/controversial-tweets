{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.wrappers import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet.tweet import Tweet\n",
    "from preprocessing import preprocessing, tree_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 2.06 s, total: 1min 13s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelw2v = KeyedVectors.load_word2vec_format(\"../model/SBW-vectors-300-min5.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "modelft = FastText.load_fasttext_format('../model/SENTIMENT_UBA_v4_d100.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_OUT = '../pickle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_attack = ['falso', 'mentira']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon esperado\n",
    "expected_lexicon = ['mentira', 'mentiroso', 'falso', 'mentirosa', 'verdad', 'verdadero', 'engañoso', 'mentir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primer resultado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged(tweets, root, lexicon, model, n):\n",
    "    lexicons = [lexicon]\n",
    "    tree = tree_create(tweets, root)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if 0 < i:\n",
    "            new = lexicons[i-1] + [word for word, d in model.most_similar(positive=lexicons[i-1])]\n",
    "            lexicons.append(new)\n",
    "       \n",
    "        for _, tweet in tweets.items():\n",
    "            \n",
    "            if tweet.stance == 'neutral':\n",
    "                tweet.is_attack(lexicons[i])\n",
    "            \n",
    "            if tweet.stance == 'neutral':\n",
    "                tweet.is_support()\n",
    "        \n",
    "        name = root + 'n' + str(i) + '.pkl'\n",
    "        with open(os.path.join(ROOT_OUT, name), 'wb') as fd:\n",
    "            pickle.dump(tree, fd)\n",
    "    \n",
    "    return lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n",
      "El elemento no está presente\n"
     ]
    }
   ],
   "source": [
    "tweets, root = preprocessing('perfil.status.1191780164549697536.json')\n",
    "lexicons = tagged(tweets, root, lexicon_attack, modelw2v, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['falso', 'mentira'],\n",
       " ['falso',\n",
       "  'mentira',\n",
       "  'falsa',\n",
       "  'mentirilla',\n",
       "  'verdad',\n",
       "  'fraudulencia',\n",
       "  'engaño',\n",
       "  'infundio',\n",
       "  'mentiras',\n",
       "  'andrómina',\n",
       "  'patraña',\n",
       "  'encubriéndola'],\n",
       " ['falso',\n",
       "  'mentira',\n",
       "  'falsa',\n",
       "  'mentirilla',\n",
       "  'verdad',\n",
       "  'fraudulencia',\n",
       "  'engaño',\n",
       "  'infundio',\n",
       "  'mentiras',\n",
       "  'andrómina',\n",
       "  'patraña',\n",
       "  'encubriéndola',\n",
       "  'embaucamiento',\n",
       "  'inauténtica',\n",
       "  'mangancia',\n",
       "  'autocondena',\n",
       "  'extrañándose',\n",
       "  'tacharme',\n",
       "  'trola',\n",
       "  'fechorias',\n",
       "  'trocaré',\n",
       "  'desverguenza']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNA IDEA PRIMERO CALCULAR LOS LEXICONES Y DESPUES TAGGEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEA FRANCO:\n",
    "\n",
    "1- AGRANDO LEXICON A PARTIR DEL MODELO DE CRISTIAN\n",
    "\n",
    "2- CALCULO UN UMBRAL DEL MODELO DE CRISTIAN\n",
    "\n",
    "3- PARA CADA (PALABRAL, TOKENT) DEL LEXICON X TWEET, SI DISTANCIA(PALABRAL, TOKENT) > UMBRAL ENTONCES LEXICON + TOKENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taggedcross(modelft, tweets, root, lexicon, u, n):\n",
    "    \n",
    "    lexicons = [lexicon]\n",
    "    #tree = tree_create(tweets, root)\n",
    "    for i in range(n):\n",
    "        new = lexicons[i]\n",
    "        for _, tweet in tweets.items():\n",
    "            \n",
    "            merge = product(lexicons[i], tweet.tokens)\n",
    "\n",
    "            for wordl, token in list(merge):\n",
    "                if wordl and token in modelft.wv.vocab:\n",
    "                    if modelft.similarity(wordl, token) >= u:\n",
    "                        if token not in lexicon_attack:\n",
    "                            new.append(token)\n",
    "        \n",
    "        lexicons.append(new)\n",
    "    return lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, root = preprocessing('perfil.status.1191780164549697536.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = taggedcross(modelft, tweets, root, lexicon_attack, 0.65, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lexicons[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = filter(lambda x: x in modelw2v.vocab, lexicon_attack)\n",
    "lexicon_attack += [word for word, d in modelw2v.most_similar(positive=w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lexicon_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "print('BLEU score: {}'.format(bleu.sentence_bleu(tree.replies[19].tokens, tree.tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API TWITTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'tRe3ZBhnXDPBEKyTi4ifvPTC7' \n",
    "CONSUMER_SECRET = '0dmQlSimyEmaOPiDoFZTF0wYjO0LSzSdWmCP7afZkNHZF94Af5'\n",
    "ACCESS_TOKEN = '421837149-YVewRWLSu8xyYNU1H4NtELUejGB8lzvT4KCfallG'\n",
    "ACCESS_SECRET = 'mFsKYpvJaWvZGHRoy874Z4IF09CRP69srlVj2yjN6mH5L'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
