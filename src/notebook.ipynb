{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tweet import Tweet, PostNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PICKLE = '../pickle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_attack = ['falso', 'Falso', 'FALSO']\n",
    "lexicon_support = ['verdad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primer resultado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir tweets del post, estoy guardando todos como si fuesen respuestas del tweet, y no lo son\n",
    "# hay tweets que son respuestas de las respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(ROOT_PICKLE, 'chequeado1186118160287698944.json.pkl'), 'rb') as fd:\n",
    "    json = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(full_text, text_range):\n",
    "    begin = text_range[0]\n",
    "    return full_text[begin:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(json):\n",
    "    replies = []\n",
    "    post = None\n",
    "    for id_str, tweet in json.items():\n",
    "        full_text = tweet['full_text']\n",
    "        created_at = tweet['created_at']\n",
    "        reply_count = tweet['reply_count']\n",
    "        conversation_id_str = tweet['conversation_id_str']\n",
    "        if id_str == tweet['conversation_id_str']:\n",
    "            post = PostNew(created_at=created_at,\n",
    "                           reply_count=reply_count,\n",
    "                           conversation_id_str=conversation_id_str,\n",
    "                           full_text=full_text\n",
    "                          )\n",
    "        else:\n",
    "            text_range = tweet['display_text_range']\n",
    "            text = get_text(full_text, text_range)\n",
    "            id_str = tweet['id_str']\n",
    "            in_reply_to_status_id_str=tweet['in_reply_to_status_id_str']\n",
    "            twt = Tweet(created_at=created_at,\n",
    "                        text=text,\n",
    "                        id_str=id_str,\n",
    "                        reply_count=reply_count,\n",
    "                        conversation_id_str=conversation_id_str,\n",
    "                        in_reply_to_status_id_str=in_reply_to_status_id_str\n",
    "                       )\n",
    "            replies.append(twt)\n",
    "    post.replies = replies\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = preprocessing(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.is_controversial(lexicon_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = post.get_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segundo resultado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUDA: que determina que palabras se agregan al lexicon, cluster viendo como testigo palabras del lexicon?, o por distancia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tercer resultado**\n",
    "\n",
    "https://plot.ly/python/tree-plots/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API TWITTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'tRe3ZBhnXDPBEKyTi4ifvPTC7' \n",
    "CONSUMER_SECRET = '0dmQlSimyEmaOPiDoFZTF0wYjO0LSzSdWmCP7afZkNHZF94Af5'\n",
    "ACCESS_TOKEN = '421837149-YVewRWLSu8xyYNU1H4NtELUejGB8lzvT4KCfallG'\n",
    "ACCESS_SECRET = 'mFsKYpvJaWvZGHRoy874Z4IF09CRP69srlVj2yjN6mH5L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = tweepy.Cursor(api.search, q=\"to:FedeFavre\", sinceId = 1188249861721919489).items()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
