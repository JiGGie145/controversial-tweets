{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.wrappers import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet.tweet import Tweet\n",
    "from preprocessing import preprocessing, tree_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 1.92 s, total: 1min 5s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelw2v = KeyedVectors.load_word2vec_format(\"../model/SBW-vectors-300-min5.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_OUT = '../pickle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_attack = ['falso', 'mentira']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primer resultado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged(tweets, root, lexicon, model, n):\n",
    "    lexicons = [lexicon]\n",
    "    tree = tree_create(tweets, root)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if 0 < i:\n",
    "            new = lexicons[i-1] + [word for word, d in model.most_similar(positive=lexicons[i-1])]\n",
    "            lexicons.append(new)\n",
    "       \n",
    "        for _, tweet in tweets.items():\n",
    "            tweet.is_attack(lexicons[i])\n",
    "                   \n",
    "        name = root + 'n' + str(i) + '.pkl'\n",
    "        with open(os.path.join(ROOT_OUT, name), 'wb') as fd:\n",
    "            pickle.dump(tree, fd)\n",
    "    \n",
    "    return lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets, root = preprocessing('perfil.status.1191780164549697536.json')\n",
    "lexicons = tagged(tweets, root, lexicon_attack, modelw2v, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEA FRANCO:\n",
    "\n",
    "1- AGRANDO LEXICON A PARTIR DEL MODELO DE CRISTIAN\n",
    "\n",
    "2- CALCULO UN UMBRAL DEL MODELO DE CRISTIAN\n",
    "\n",
    "3- PARA CADA (PALABRAL, TOKENT) DEL LEXICON X TWEET, SI DISTANCIA(PALABRAL, TOKENT) > UMBRAL ENTONCES LEXICON + TOKENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMBRAL = 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, tweet in tweets.items():\n",
    "    merge = product(lexicon_attack, tweet.tokens)\n",
    "    for wordl, token in list(merge):\n",
    "        if wordl and token in model.wv.vocab:\n",
    "            if model.similarity(wordl, token) >= UMBRAL:\n",
    "                if token not in lexicon_attack:\n",
    "                    lexicon_attack.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lexicon_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = filter(lambda x: x in modelw2v.vocab, lexicon_attack)\n",
    "lexicon_attack += [word for word, d in modelw2v.most_similar(positive=w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lexicon_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "print('BLEU score: {}'.format(bleu.sentence_bleu(tree.replies[19].tokens, tree.tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API TWITTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'tRe3ZBhnXDPBEKyTi4ifvPTC7' \n",
    "CONSUMER_SECRET = '0dmQlSimyEmaOPiDoFZTF0wYjO0LSzSdWmCP7afZkNHZF94Af5'\n",
    "ACCESS_TOKEN = '421837149-YVewRWLSu8xyYNU1H4NtELUejGB8lzvT4KCfallG'\n",
    "ACCESS_SECRET = 'mFsKYpvJaWvZGHRoy874Z4IF09CRP69srlVj2yjN6mH5L'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
